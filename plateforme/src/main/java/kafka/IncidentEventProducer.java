package kafka;

import com.polysteam.plateforme.events.RapportIncidentEvent;
import io.confluent.kafka.serializers.KafkaAvroSerializer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.io.IOException;
import java.net.HttpURLConnection;
import java.net.URL;
import java.util.Properties;
import java.util.UUID;

/**
 * Producer Kafka pour publier les √©v√©nements de rapports d'incidents
 * Utilise Avro pour la s√©rialisation des messages
 */
public class IncidentEventProducer {

    private static final String KAFKA_BOOTSTRAP_SERVERS = "86.252.172.215:9092";
    private static final String SCHEMA_REGISTRY_URL = "http://86.252.172.215:8081";
    private static final String TOPIC_NAME = "plateforme.incidents";

    private final KafkaProducer<String, RapportIncidentEvent> producer;

    public IncidentEventProducer() {
        this.producer = new KafkaProducer<>(createProducerConfig());
        System.out.println("‚úÖ Kafka Producer initialis√©");

        // Tester la connexion
        testConnection();
    }

    /**
     * Test de connexion √† Kafka et Schema Registry
     */
    private void testConnection() {
        // Test 1: Connexion √† Kafka
        try {
            System.out.println("üîç Test de connexion √† Kafka...");
            producer.partitionsFor(TOPIC_NAME);
            System.out.println("‚úÖ Connexion √† Kafka r√©ussie !");
        } catch (Exception e) {
            System.err.println("‚ö†Ô∏è  Attention : Impossible de se connecter √† Kafka");
            System.err.println("    Erreur : " + e.getMessage());
            System.err.println("    V√©rifiez que Kafka est accessible sur " + KAFKA_BOOTSTRAP_SERVERS);
        }

        // Test 2: Connexion au Schema Registry
        try {
            System.out.println("üîç Test de connexion au Schema Registry...");
            URL url = new URL(SCHEMA_REGISTRY_URL);
            HttpURLConnection connection = (HttpURLConnection) url.openConnection();
            connection.setRequestMethod("GET");
            connection.setConnectTimeout(5000);
            connection.setReadTimeout(5000);

            int responseCode = connection.getResponseCode();
            if (responseCode == 200) {
                System.out.println("‚úÖ Connexion au Schema Registry r√©ussie !");
            } else {
                System.err.println("‚ö†Ô∏è  Schema Registry r√©pond avec le code: " + responseCode);
            }
            connection.disconnect();
        } catch (IOException e) {
            System.err.println("‚ùå ERREUR CRITIQUE : Schema Registry inaccessible !");
            System.err.println("    URL test√©e : " + SCHEMA_REGISTRY_URL);
            System.err.println("    Erreur : " + e.getMessage());
            System.err.println("    ‚ö†Ô∏è  Les messages Kafka avec Avro ne pourront PAS √™tre envoy√©s !");
            System.err.println("    Solutions possibles :");
            System.err.println("    1. V√©rifiez que Schema Registry est d√©marr√© sur le serveur");
            System.err.println("    2. V√©rifiez les r√®gles de firewall (port 8081)");
            System.err.println("    3. Utilisez un tunnel SSH si n√©cessaire");
        }

        System.out.println();
    }

    /**
     * Configuration du producer Kafka avec Avro
     */
    private Properties createProducerConfig() {
        Properties props = new Properties();

        // Configuration Kafka de base
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, KAFKA_BOOTSTRAP_SERVERS);
        props.put(ProducerConfig.CLIENT_ID_CONFIG, "plateforme-producer");

        // S√©rialisation : String pour la cl√©, Avro pour la valeur
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, KafkaAvroSerializer.class.getName());

        // Schema Registry pour la gestion des sch√©mas Avro
        props.put("schema.registry.url", SCHEMA_REGISTRY_URL);

        // Configuration pour la fiabilit√© avec timeouts AUGMENT√âS
        props.put(ProducerConfig.ACKS_CONFIG, "all"); // OBLIGATOIRE avec idempotence
        props.put(ProducerConfig.RETRIES_CONFIG, Integer.MAX_VALUE); // R√©essais infinis
        props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, "true"); // √âviter les doublons
        props.put(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, 5); // Garder l'ordre

        // Timeouts AUGMENT√âS pour r√©seau distant/lent
        props.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 60000); // 60 secondes
        props.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, 60000); // 60 secondes
        props.put(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG, 120000); // 120 secondes

        // Configuration r√©seau pour connexions distantes
        props.put(ProducerConfig.LINGER_MS_CONFIG, 100); // Attendre 100ms avant d'envoyer (batching)
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, 16384); // Taille du batch
        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 33554432); // 32MB de buffer

        // Compression pour r√©duire la bande passante
        props.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy");

        // D√©sactiver la r√©solution DNS automatique (forcer l'utilisation de l'IP donn√©e)
        props.put("metadata.max.age.ms", 300000); // 5 minutes
        props.put("connections.max.idle.ms", 540000); // 9 minutes

        return props;
    }

    /**
     * Publie un √©v√©nement de rapport d'incident sur Kafka
     * @param jeuId Identifiant du jeu
     * @param titreJeu Titre du jeu
     * @param editeurId Identifiant de l'√©diteur
     * @param versionJeu Version du jeu
     * @param plateforme Plateforme (PC, PS5, etc.)
     * @param pseudoJoueur Pseudo du joueur
     * @param typeIncident Type d'incident (CRASH, FREEZE, etc.)
     * @param description Description de l'incident
     */
    public void publierIncident(
        String jeuId,
        String titreJeu,
        String editeurId,
        String versionJeu,
        String plateforme,
        String pseudoJoueur,
        String typeIncident,
        String description
    ) {
        try {
            System.out.println("  üî® Cr√©ation de l'√©v√©nement Avro...");

            // Cr√©er l'√©v√©nement Avro
            RapportIncidentEvent event = RapportIncidentEvent.newBuilder()
                .setEventId(UUID.randomUUID().toString())
                .setTimestamp(System.currentTimeMillis())
                .setIncidentId(UUID.randomUUID().toString())
                .setJeuId(jeuId)
                .setTitreJeu(titreJeu)
                .setEditeurId(editeurId)
                .setVersionJeu(versionJeu)
                .setPlateforme(plateforme)
                .setPseudoJoueur(pseudoJoueur)
                .setTypeIncident(com.polysteam.plateforme.events.TypeIncident.valueOf(typeIncident))
                .setDescriptionErreur(description)
                .setDateSurvenue(System.currentTimeMillis())
                .setContexte(null) // Optionnel
                .build();

            System.out.println("  ‚úÖ √âv√©nement Avro cr√©√© avec succ√®s");
            System.out.println("  üì§ Envoi vers Kafka (topic: " + TOPIC_NAME + ")...");

            // Cr√©er le record Kafka
            ProducerRecord<String, RapportIncidentEvent> record =
                new ProducerRecord<>(TOPIC_NAME, editeurId, event);

            // Publier de mani√®re SYNCHRONE avec callback pour plus de d√©tails
            var future = producer.send(record, (metadata, exception) -> {
                if (exception != null) {
                    System.err.println("  ‚ùå Erreur callback : " + exception.getMessage());
                    exception.printStackTrace();
                } else {
                    System.out.println("  ‚úÖ Message re√ßu par Kafka ! (partition: " + metadata.partition() +
                        ", offset: " + metadata.offset() + ")");
                }
            });

            // Attendre la r√©ponse (bloquant)
            System.out.println("  ‚è≥ Attente de la confirmation Kafka...");
            future.get(); // ‚Üê SYNCHRONE : attend la r√©ponse

            System.out.println("‚úÖ Incident publi√© avec succ√®s : " + titreJeu);

        } catch (org.apache.kafka.common.errors.TimeoutException e) {
            System.err.println("‚ùå KAFKA TIMEOUT : Expiration du message");
            System.err.println("    Jeu : " + titreJeu);
            System.err.println("    D√©tails : " + e.getMessage());
            System.err.println("    Le broker Kafka ne r√©pond pas assez vite");

        } catch (Exception e) {
            System.err.println("‚ùå Erreur lors de l'envoi de l'incident : " + titreJeu);
            System.err.println("    Type d'erreur : " + e.getClass().getName());
            System.err.println("    Message : " + e.getMessage());

            // Afficher la cause racine si elle existe
            if (e.getCause() != null) {
                System.err.println("    Cause racine : " + e.getCause().getClass().getName());
                System.err.println("    D√©tails cause : " + e.getCause().getMessage());
            }
        }
    }

    /**
     * Version ASYNCHRONE de la publication (fire-and-forget)
     * Plus rapide mais sans garantie imm√©diate
     */
    public void publierIncidentAsync(
        String jeuId,
        String titreJeu,
        String editeurId,
        String versionJeu,
        String plateforme,
        String pseudoJoueur,
        String typeIncident,
        String description
    ) {
        try {
            System.out.println("  üî® Cr√©ation de l'√©v√©nement Avro (mode ASYNC)...");

            // Cr√©er l'√©v√©nement Avro
            RapportIncidentEvent event = RapportIncidentEvent.newBuilder()
                .setEventId(UUID.randomUUID().toString())
                .setTimestamp(System.currentTimeMillis())
                .setIncidentId(UUID.randomUUID().toString())
                .setJeuId(jeuId)
                .setTitreJeu(titreJeu)
                .setEditeurId(editeurId)
                .setVersionJeu(versionJeu)
                .setPlateforme(plateforme)
                .setPseudoJoueur(pseudoJoueur)
                .setTypeIncident(com.polysteam.plateforme.events.TypeIncident.valueOf(typeIncident))
                .setDescriptionErreur(description)
                .setDateSurvenue(System.currentTimeMillis())
                .setContexte(null)
                .build();

            System.out.println("  üì§ Envoi asynchrone vers Kafka...");

            // Cr√©er le record Kafka
            ProducerRecord<String, RapportIncidentEvent> record =
                new ProducerRecord<>(TOPIC_NAME, editeurId, event);

            // Publier en mode ASYNCHRONE avec callback
            producer.send(record, (metadata, exception) -> {
                if (exception != null) {
                    System.err.println("  ‚ùå Erreur async : " + titreJeu);
                    System.err.println("     " + exception.getMessage());
                } else {
                    System.out.println("  ‚úÖ Publi√© : " + titreJeu +
                        " (partition: " + metadata.partition() +
                        ", offset: " + metadata.offset() + ")");
                }
            });

            System.out.println("  ‚è© Message envoy√© en mode asynchrone (v√©rifiez les callbacks)");

        } catch (Exception e) {
            System.err.println("‚ùå Erreur cr√©ation √©v√©nement : " + titreJeu);
            System.err.println("    " + e.getMessage());
            e.printStackTrace();
        }
    }

    /**
     * Ferme proprement le producer (√† appeler √† la fin de l'application)
     */
    public void close() {
        if (producer != null) {
            producer.flush(); // Assurer que tous les messages en attente sont envoy√©s
            producer.close();
            System.out.println("‚úÖ Kafka Producer ferm√©");
        }
    }
}

